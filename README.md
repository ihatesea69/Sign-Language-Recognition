# ğŸ¤Ÿ Sign Language Recognition - Nháº­n Diá»‡n NgÃ´n Ngá»¯ KÃ½ Hiá»‡u

## ğŸ“‹ Tá»•ng Quan

á»¨ng dá»¥ng Python nháº­n diá»‡n ngÃ´n ngá»¯ kÃ½ hiá»‡u (ASL alphabet) vÃ  chuyá»ƒn Ä‘á»•i thÃ nh giá»ng nÃ³i Ä‘á»ƒ há»— trá»£ giao tiáº¿p cho ngÆ°á»i khiáº¿m thÃ­nh.

### ğŸ¯ Má»¥c TiÃªu
- Nháº­n diá»‡n cÃ¡c kÃ½ hiá»‡u tay (A-Z) qua camera
- Chuyá»ƒn Ä‘á»•i thÃ nh vÄƒn báº£n
- PhÃ¡t ra giá»ng nÃ³i tá»± nhiÃªn báº±ng AI

### ğŸ› ï¸ Tech Stack
- **MediaPipe Hands**: PhÃ¡t hiá»‡n vÃ  theo dÃµi bÃ n tay (21 landmarks)
- **OpenCV**: Xá»­ lÃ½ video real-time
- **OpenAI TTS**: Chuyá»ƒn vÄƒn báº£n thÃ nh giá»ng nÃ³i
- **Scikit-learn**: Training gesture classifier
- **Python 3.11**: NgÃ´n ngá»¯ chÃ­nh âš ï¸ MediaPipe khÃ´ng support Python 3.13

---

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn

```
School Computer Vision/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ hand_detector.py          # PhÃ¡t hiá»‡n bÃ n tay (21 landmarks)
â”‚   â”œâ”€â”€ gesture_classifier.py     # PhÃ¢n loáº¡i kÃ½ hiá»‡u A-Z
â”‚   â”œâ”€â”€ text_to_speech.py         # OpenAI TTS integration
â”‚   â””â”€â”€ main.py                   # á»¨ng dá»¥ng chÃ­nh
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py                 # Quáº£n lÃ½ cáº¥u hÃ¬nh
â”‚   â””â”€â”€ helpers.py                # UI utilities
â”œâ”€â”€ models/                       # ML models (sau khi train)
â”œâ”€â”€ data/                         # Training/testing data
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ testing/
â”œâ”€â”€ .env                          # API keys & settings
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # Documentation nÃ y
â””â”€â”€ MEMORY.md                     # Ghi chÃº cho AI
```

---

## ğŸ”„ Workflow

```
Camera â†’ MediaPipe Hands â†’ Classifier â†’ Speech Buffer â†’ OpenAI TTS
  ğŸ¥         ğŸ‘‹ (21 pts)       A-Z        "HELLO"         ğŸ”Š
```

**Chi tiáº¿t:**
1. **Camera**: Capture video frame
2. **Hand Detector**: Detect hand â†’ 21 landmarks (x, y coordinates)
3. **Gesture Classifier**: Landmarks â†’ Letter prediction (A, B, C... + confidence)
4. **Speech Buffer**: Accumulate letters into words
5. **Text-to-Speech**: Convert text to voice

---

## ğŸš€ Quick Start

### 1. Fix Python Version âš ï¸ IMPORTANT
**MediaPipe chá»‰ há»— trá»£ Python 3.8 - 3.11**

```powershell
# Download Python 3.11 tá»« python.org
# Táº¡o virtual environment:
py -3.11 -m venv venv
.\venv\Scripts\activate
```

### 2. CÃ i Äáº·t Dependencies

```powershell
pip install --upgrade pip
pip install -r requirements.txt
```

### 3. Cáº¥u HÃ¬nh

```powershell
copy .env.example .env
# Edit .env: ThÃªm OPENAI_API_KEY=your-key-here
```

### 4. Test

```powershell
# Test hand detection
python src/hand_detector.py

# Test TTS (cáº§n API key)
python src/text_to_speech.py

# Run full app
python src/main.py
```

---

## ğŸ® Keyboard Controls

| Key | Action |
|-----|--------|
| `SPACE` | ThÃªm space giá»¯a cÃ¡c tá»« |
| `ENTER` | Speak text hiá»‡n táº¡i |
| `BACKSPACE` | XÃ³a kÃ½ tá»± cuá»‘i |
| `C` | Clear all text |
| `P` | Pause/Resume |
| `Q` | Quit |

---

## ğŸ“Š Káº¿ Hoáº¡ch 8 Tuáº§n

### Week 1-2: Setup âœ… DONE
- [x] Project structure
- [x] Hand detector module
- [x] Basic modules

### Week 3-4: Data & Training ğŸ”„ CURRENT
- [ ] Data collection tool
- [ ] Collect 100+ samples/letter (A-Z)
- [ ] Train classifier (target: 85% accuracy)

### Week 5: TTS Integration
- [ ] Complete OpenAI TTS
- [ ] Speech buffer system
- [ ] Word completion logic

### Week 6: UI/UX
- [ ] User interface
- [ ] Visual feedback
- [ ] Settings panel

### Week 7-8: Testing & Polish
- [ ] Unit tests
- [ ] User testing
- [ ] Performance optimization
- [ ] Documentation

---

## ğŸ’» Code Examples

### Hand Detection
```python
from hand_detector import HandDetector
import cv2

detector = HandDetector(max_hands=1, detection_confidence=0.7)
cap = cv2.VideoCapture(0)

while True:
    success, img = cap.read()
    img = detector.find_hands(img, draw=True)
    landmarks = detector.find_position(img)
    
    if landmarks:
        print(f"Found {len(landmarks)} landmarks")
    
    cv2.imshow("Hand Detection", img)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
```

### Gesture Classification
```python
from gesture_classifier import GestureClassifier

classifier = GestureClassifier(model_path="models/gesture_model.pkl")
gesture, confidence = classifier.classify_gesture(landmarks)
print(f"Detected: {gesture} (confidence: {confidence:.2f})")
```

### Text-to-Speech
```python
from text_to_speech import TextToSpeech

tts = TextToSpeech(api_key="your-key", voice="alloy")
tts.text_to_speech("Hello World")  # ğŸ”Š
```

---

## ğŸ› Troubleshooting

### MediaPipe Install Error
**Problem**: `Could not find mediapipe`  
**Solution**: Python version pháº£i lÃ  3.8-3.11 (khÃ´ng pháº£i 3.13)

```powershell
python --version  # Check version
py -3.11 -m venv venv  # Use Python 3.11
```

### Camera Not Working
**Problem**: Camera khÃ´ng má»Ÿ  
**Solution**: Thá»­ Ä‘á»•i `CAMERA_INDEX` trong .env (0, 1, 2...)

### Low FPS
**Problem**: FPS < 20  
**Solution**: Giáº£m resolution
```python
CAMERA_WIDTH=640
CAMERA_HEIGHT=480
```

### OpenAI API Error
**Problem**: TTS khÃ´ng work  
**Solution**: 
- Check API key Ä‘Ãºng
- Verify account cÃ³ credits
- Check internet connection

---

## ğŸ“¦ Dependencies

```txt
opencv-python>=4.8.0          # Video processing
mediapipe>=0.10.0             # Hand detection
numpy>=1.24.0                 # Numerical computing
openai>=1.0.0                 # Text-to-Speech
pygame>=2.5.0                 # Audio playback
scikit-learn>=1.3.0           # ML classification
python-dotenv>=1.0.0          # Environment variables
tqdm>=4.65.0                  # Progress bars
loguru>=0.7.0                 # Logging
```

---

## ğŸ¯ Success Metrics

| Metric | Target |
|--------|--------|
| Hand Detection FPS | >= 30 FPS |
| Gesture Accuracy | >= 85% |
| TTS Latency | < 2 seconds |
| System Stability | No crash 30min |

---

## ğŸ”§ Configuration (.env)

```bash
# OpenAI
OPENAI_API_KEY=your_api_key_here

# Camera
CAMERA_INDEX=0
CAMERA_WIDTH=1280
CAMERA_HEIGHT=720

# MediaPipe
MIN_DETECTION_CONFIDENCE=0.7
MIN_TRACKING_CONFIDENCE=0.5

# Gesture Recognition
GESTURE_CONFIDENCE_THRESHOLD=0.8
BUFFER_SIZE=30

# TTS
TTS_MODEL=tts-1
TTS_VOICE=alloy  # Options: alloy, echo, fable, onyx, nova, shimmer

# App
DEBUG_MODE=False
SHOW_FPS=True
```

---

## ğŸ“š Learning Resources

- [MediaPipe Hands Docs](https://google.github.io/mediapipe/solutions/hands.html)
- [ASL Alphabet](https://www.startasl.com/american-sign-language-alphabet/)
- [OpenAI TTS API](https://platform.openai.com/docs/guides/text-to-speech)
- [Scikit-learn](https://scikit-learn.org/stable/)

---

## ğŸ¯ Next Steps

### This Week
1. Fix Python version (3.13 â†’ 3.11)
2. Install MediaPipe successfully
3. Test hand detection

### Week 3-4
4. Create data collection tool
5. Collect training data (A-Z)
6. Train classifier model

### Week 5+
7. Integrate TTS
8. Polish UI
9. User testing

---

## ğŸ“ Known Issues

1. **Python 3.13**: MediaPipe chÆ°a support â†’ Cáº§n 3.11
2. **No Trained Model**: Cáº§n collect data vÃ  train
3. **Static Only**: Chá»‰ nháº­n diá»‡n static gestures (A-Z)
4. **ASL Only**: ChÆ°a support Vietnamese Sign Language

---

## ğŸ¤ Contributing

Improvements welcome:
- Data collection
- Model optimization
- New features
- Bug fixes
- Documentation

---

## ğŸ“„ License
MIT License

---

## ğŸ“ Support

- Check [MEMORY.md](MEMORY.md) for AI context
- Review code comments in src/
- Google error vá»›i "MediaPipe" hoáº·c "OpenCV"

---

**Version**: 0.1.0 (MVP Phase)  
**Last Updated**: October 13, 2025  
**Status**: Development - Hand Detection Working âœ…
